{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28814e27",
   "metadata": {},
   "source": [
    "## A. Train on EN data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5fc39",
   "metadata": {},
   "source": [
    "### 1. Monolingual PLM (RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b70730",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python mlm_finetuning.py --dataset-dir \"../data\" \\\n",
    "    --train-filename \"mtob_domain_en_fr_train.csv\" --val-filename \"mtob_domain_en_fr_val.csv\" \\\n",
    "    --model-name \"roberta\" --language \"english\" --output-dir \"../outputs/en_only\" --run-name \"roberta-1\" \\\n",
    "    --model-max-length 50 --train-batch-size 128 --eval-batch-size 256 --learning-rate 0.00002 \\\n",
    "    --num-epochs 20 --eval-steps 100 --save-steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSLATE-TEST\n",
    "! python mlm_inference.py \\\n",
    "    --dataset-path \"../data/mtob_domain_en2fr_nllb_test.csv\" \\\n",
    "    --text-column \"text_fr2en\" \\\n",
    "    --model-path \"../outputs/en_only/roberta-1/checkpoint-600/\" \\\n",
    "    --output-path \"../outputs/en_only/roberta-1/translate_test_preds.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9999f",
   "metadata": {},
   "source": [
    "### 2. Multilingual PLM (XLM-RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b62a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device\n",
      "11 classes: ['messaging', 'calling', 'event', 'timer', 'music', 'weather', 'alarm', 'people', 'reminder', 'recipes', 'news']\n",
      "Initializer tokenizer for FacebookAI/xlm-roberta-base\n",
      "Map: 100%|██████████████████████| 11814/11814 [00:00<00:00, 14056.66 examples/s]\n",
      "Map: 100%|████████████████████████| 1577/1577 [00:00<00:00, 18050.08 examples/s]\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loaded model from FacebookAI/xlm-roberta-base\n",
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"messaging\",\n",
      "    \"1\": \"calling\",\n",
      "    \"2\": \"event\",\n",
      "    \"3\": \"timer\",\n",
      "    \"4\": \"music\",\n",
      "    \"5\": \"weather\",\n",
      "    \"6\": \"alarm\",\n",
      "    \"7\": \"people\",\n",
      "    \"8\": \"reminder\",\n",
      "    \"9\": \"recipes\",\n",
      "    \"10\": \"news\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"alarm\": 6,\n",
      "    \"calling\": 1,\n",
      "    \"event\": 2,\n",
      "    \"messaging\": 0,\n",
      "    \"music\": 4,\n",
      "    \"news\": 10,\n",
      "    \"people\": 7,\n",
      "    \"recipes\": 9,\n",
      "    \"reminder\": 8,\n",
      "    \"timer\": 3,\n",
      "    \"weather\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Trainable params: 278052107 || all params: 278052107 || trainable%: 100.0\n",
      "Saving outputs to ../outputs/en_only/xlmr-en-1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manupath\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/anupath/wn24/si630/project/scripts/wandb/run-20240426_200004-bla0p4uf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mxlmr-en-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project/runs/bla0p4uf\u001b[0m\n",
      "  5%|██▏                                     | 100/1860 [00:25<07:19,  4.00it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.40it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.19it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.15035147964954376, 'eval_f1': 0.9733671528218135, 'eval_precision': 0.9733671528218135, 'eval_recall': 0.9733671528218135, 'eval_macro_f1': 0.971344901435759, 'eval_weighted_f1': 0.9731623203379136, 'eval_runtime': 0.6734, 'eval_samples_per_second': 2341.869, 'eval_steps_per_second': 10.395, 'epoch': 1.08}\n",
      "  5%|██▏                                     | 100/1860 [00:26<07:19,  4.00it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.13it/s]\u001b[A\n",
      " 11%|████▎                                   | 200/1860 [01:04<06:59,  3.96it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.63it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.27it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.05644267797470093, 'eval_f1': 0.9873176918199112, 'eval_precision': 0.9873176918199112, 'eval_recall': 0.9873176918199112, 'eval_macro_f1': 0.9859944606052617, 'eval_weighted_f1': 0.9873536066574776, 'eval_runtime': 0.6728, 'eval_samples_per_second': 2344.063, 'eval_steps_per_second': 10.405, 'epoch': 2.15}\n",
      " 11%|████▎                                   | 200/1860 [01:05<06:59,  3.96it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.11it/s]\u001b[A\n",
      " 16%|██████▍                                 | 300/1860 [01:46<06:35,  3.95it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.52it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.034694854170084, 'eval_f1': 0.9923906150919467, 'eval_precision': 0.9923906150919467, 'eval_recall': 0.9923906150919467, 'eval_macro_f1': 0.9914138054545422, 'eval_weighted_f1': 0.9923900612780393, 'eval_runtime': 0.6759, 'eval_samples_per_second': 2333.28, 'eval_steps_per_second': 10.357, 'epoch': 3.23}\n",
      " 16%|██████▍                                 | 300/1860 [01:47<06:35,  3.95it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.07it/s]\u001b[A\n",
      " 22%|████████▌                               | 400/1860 [02:22<06:11,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.36it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.13it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.0263199619948864, 'eval_f1': 0.9949270767279645, 'eval_precision': 0.9949270767279645, 'eval_recall': 0.9949270767279645, 'eval_macro_f1': 0.994179532173754, 'eval_weighted_f1': 0.9949197694269389, 'eval_runtime': 0.6764, 'eval_samples_per_second': 2331.559, 'eval_steps_per_second': 10.349, 'epoch': 4.3}\n",
      " 22%|████████▌                               | 400/1860 [02:23<06:11,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.03it/s]\u001b[A\n",
      "{'loss': 0.3198, 'grad_norm': 0.08287491649389267, 'learning_rate': 1.4623655913978497e-05, 'epoch': 5.38}\n",
      " 27%|██████████▊                             | 500/1860 [03:00<05:46,  3.92it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.53it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.24it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.040263306349515915, 'eval_f1': 0.9904882688649335, 'eval_precision': 0.9904882688649335, 'eval_recall': 0.9904882688649335, 'eval_macro_f1': 0.9889129857123475, 'eval_weighted_f1': 0.9905150009041184, 'eval_runtime': 0.6491, 'eval_samples_per_second': 2429.548, 'eval_steps_per_second': 10.784, 'epoch': 5.38}\n",
      " 27%|██████████▊                             | 500/1860 [03:00<05:46,  3.92it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.11it/s]\u001b[A\n",
      " 32%|████████████▉                           | 600/1860 [03:38<05:20,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.09it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.037012502551078796, 'eval_f1': 0.9911223842739378, 'eval_precision': 0.9911223842739378, 'eval_recall': 0.9911223842739378, 'eval_macro_f1': 0.9900281804719101, 'eval_weighted_f1': 0.9911146766800191, 'eval_runtime': 0.6791, 'eval_samples_per_second': 2322.082, 'eval_steps_per_second': 10.307, 'epoch': 6.45}\n",
      " 32%|████████████▉                           | 600/1860 [03:38<05:20,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 10.99it/s]\u001b[A\n",
      " 38%|███████████████                         | 700/1860 [04:19<04:55,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.03360576927661896, 'eval_f1': 0.9930247305009512, 'eval_precision': 0.9930247305009512, 'eval_recall': 0.9930247305009512, 'eval_macro_f1': 0.9921627093728698, 'eval_weighted_f1': 0.9930498977360916, 'eval_runtime': 0.6752, 'eval_samples_per_second': 2335.674, 'eval_steps_per_second': 10.368, 'epoch': 7.53}\n",
      " 38%|███████████████                         | 700/1860 [04:20<04:55,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.06it/s]\u001b[A\n",
      " 43%|█████████████████▏                      | 800/1860 [05:01<04:29,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.38it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.16it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.03200908750295639, 'eval_f1': 0.9923906150919467, 'eval_precision': 0.9923906150919467, 'eval_recall': 0.9923906150919467, 'eval_macro_f1': 0.9913798604904976, 'eval_weighted_f1': 0.9923883089093419, 'eval_runtime': 0.6753, 'eval_samples_per_second': 2335.153, 'eval_steps_per_second': 10.365, 'epoch': 8.6}\n",
      " 43%|█████████████████▏                      | 800/1860 [05:02<04:29,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.05it/s]\u001b[A\n",
      " 48%|███████████████████▎                    | 900/1860 [05:43<04:03,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.40it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.21it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.032191984355449677, 'eval_f1': 0.9942929613189601, 'eval_precision': 0.9942929613189601, 'eval_recall': 0.9942929613189601, 'eval_macro_f1': 0.9935628877385476, 'eval_weighted_f1': 0.9942962477965236, 'eval_runtime': 0.6746, 'eval_samples_per_second': 2337.634, 'eval_steps_per_second': 10.376, 'epoch': 9.68}\n",
      " 48%|███████████████████▎                    | 900/1860 [05:43<04:03,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.09it/s]\u001b[A\n",
      "{'loss': 0.0101, 'grad_norm': 2.9985456466674805, 'learning_rate': 9.24731182795699e-06, 'epoch': 10.75}\n",
      " 54%|████████████████████▉                  | 1000/1860 [06:24<03:38,  3.94it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.02it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.02it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.03333044797182083, 'eval_f1': 0.9936588459099556, 'eval_precision': 0.9936588459099556, 'eval_recall': 0.9936588459099556, 'eval_macro_f1': 0.9930255203467145, 'eval_weighted_f1': 0.9936662708007082, 'eval_runtime': 0.6552, 'eval_samples_per_second': 2407.04, 'eval_steps_per_second': 10.684, 'epoch': 10.75}\n",
      " 54%|████████████████████▉                  | 1000/1860 [06:24<03:38,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.00it/s]\u001b[A\n",
      " 59%|███████████████████████                | 1100/1860 [07:01<03:12,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.41it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.02903846465051174, 'eval_f1': 0.9942929613189601, 'eval_precision': 0.9942929613189601, 'eval_recall': 0.9942929613189601, 'eval_macro_f1': 0.9935524310978985, 'eval_weighted_f1': 0.9942954985467087, 'eval_runtime': 0.6754, 'eval_samples_per_second': 2334.757, 'eval_steps_per_second': 10.364, 'epoch': 11.83}\n",
      " 59%|███████████████████████                | 1100/1860 [07:02<03:12,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.06it/s]\u001b[A\n",
      " 65%|█████████████████████████▏             | 1200/1860 [07:42<02:47,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.48it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.21it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.036452434957027435, 'eval_f1': 0.9930247305009512, 'eval_precision': 0.9930247305009512, 'eval_recall': 0.9930247305009512, 'eval_macro_f1': 0.9923526303479853, 'eval_weighted_f1': 0.9930266102629635, 'eval_runtime': 0.6723, 'eval_samples_per_second': 2345.571, 'eval_steps_per_second': 10.412, 'epoch': 12.9}\n",
      " 65%|█████████████████████████▏             | 1200/1860 [07:42<02:47,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.12it/s]\u001b[A\n",
      " 70%|███████████████████████████▎           | 1300/1860 [08:23<02:21,  3.95it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.45it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.21it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.037804946303367615, 'eval_f1': 0.9936588459099556, 'eval_precision': 0.9936588459099556, 'eval_recall': 0.9936588459099556, 'eval_macro_f1': 0.9928445949845135, 'eval_weighted_f1': 0.993660125127548, 'eval_runtime': 0.6734, 'eval_samples_per_second': 2341.9, 'eval_steps_per_second': 10.395, 'epoch': 13.98}\n",
      " 70%|███████████████████████████▎           | 1300/1860 [08:23<02:21,  3.95it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████▎         | 1400/1860 [08:58<01:53,  4.05it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.45it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.032574959099292755, 'eval_f1': 0.9942929613189601, 'eval_precision': 0.9942929613189601, 'eval_recall': 0.9942929613189601, 'eval_macro_f1': 0.9937467179867937, 'eval_weighted_f1': 0.9942949294104033, 'eval_runtime': 0.6776, 'eval_samples_per_second': 2327.421, 'eval_steps_per_second': 10.331, 'epoch': 15.05}\n",
      " 75%|█████████████████████████████▎         | 1400/1860 [08:59<01:53,  4.05it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.02it/s]\u001b[A\n",
      "{'loss': 0.0026, 'grad_norm': 0.00847059115767479, 'learning_rate': 3.870967741935484e-06, 'epoch': 16.13}\n",
      " 81%|███████████████████████████████▍       | 1500/1860 [09:35<01:31,  3.94it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.19it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.03it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.028339538723230362, 'eval_f1': 0.9955611921369689, 'eval_precision': 0.9955611921369689, 'eval_recall': 0.9955611921369689, 'eval_macro_f1': 0.9953435521312365, 'eval_weighted_f1': 0.9955632988363682, 'eval_runtime': 0.6545, 'eval_samples_per_second': 2409.54, 'eval_steps_per_second': 10.695, 'epoch': 16.13}\n",
      " 81%|███████████████████████████████▍       | 1500/1860 [09:35<01:31,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.02it/s]\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 1600/1860 [10:11<01:06,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.48it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.20it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.02878216840326786, 'eval_f1': 0.9949270767279645, 'eval_precision': 0.9949270767279645, 'eval_recall': 0.9949270767279645, 'eval_macro_f1': 0.9945094888988183, 'eval_weighted_f1': 0.994928277434887, 'eval_runtime': 0.6756, 'eval_samples_per_second': 2334.356, 'eval_steps_per_second': 10.362, 'epoch': 17.2}\n",
      " 86%|█████████████████████████████████▌     | 1600/1860 [10:12<01:06,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.08it/s]\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 1700/1860 [10:50<00:40,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.11it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.03016182966530323, 'eval_f1': 0.9942929613189601, 'eval_precision': 0.9942929613189601, 'eval_recall': 0.9942929613189601, 'eval_macro_f1': 0.99401752426229, 'eval_weighted_f1': 0.9942947625703025, 'eval_runtime': 0.677, 'eval_samples_per_second': 2329.56, 'eval_steps_per_second': 10.34, 'epoch': 18.28}\n",
      " 91%|███████████████████████████████████▋   | 1700/1860 [10:51<00:40,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.03it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████▋ | 1800/1860 [11:28<00:15,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 19.30it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00, 12.10it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.03003121353685856, 'eval_f1': 0.9942929613189601, 'eval_precision': 0.9942929613189601, 'eval_recall': 0.9942929613189601, 'eval_macro_f1': 0.9937467179867937, 'eval_weighted_f1': 0.9942949294104033, 'eval_runtime': 0.68, 'eval_samples_per_second': 2319.106, 'eval_steps_per_second': 10.294, 'epoch': 19.35}\n",
      " 97%|█████████████████████████████████████▋ | 1800/1860 [11:28<00:15,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 11.01it/s]\u001b[A\n",
      "{'train_runtime': 721.5437, 'train_samples_per_second': 327.465, 'train_steps_per_second': 2.578, 'train_loss': 0.08967158126254235, 'epoch': 20.0}\n",
      "100%|███████████████████████████████████████| 1860/1860 [11:58<00:00,  2.59it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 ▁▅▇█▆▇▇▇█▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss █▃▁▁▂▂▁▁▁▁▁▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/macro_f1 ▁▅▇█▆▆▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision ▁▅▇█▆▇▇▇█▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall ▁▅▇█▆▇▇▇█▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ▇▆▇▇▁█▇▇▇▂▇▆▇▇▂▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▂▃▂▂█▁▂▂▂▇▂▃▂▂▇▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▂▃▂▂█▁▂▂▂▇▂▃▂▂▇▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/weighted_f1 ▁▅▇█▆▇▇▇█▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/f1 0.99429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 0.03003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/macro_f1 0.99375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/precision 0.99429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/recall 0.99429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 0.68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 2319.106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 10.294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/weighted_f1 0.99429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 5585846824277280.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 1860\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.00847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.0026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.08967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 721.5437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 327.465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 2.578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mxlmr-en-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project/runs/bla0p4uf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240426_200004-bla0p4uf/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python mlm_finetuning.py --dataset-dir \"../data\" \\\n",
    "    --train-filename \"mtob_domain_en_fr_train.csv\" --val-filename \"mtob_domain_en_fr_val.csv\" \\\n",
    "    --model-name \"xlm-roberta\" --language \"english\" --output-dir \"../outputs/en_only\" --run-name \"xlmr-en-1\" \\\n",
    "    --model-max-length 50 --train-batch-size 128 --eval-batch-size 256 --learning-rate 0.00002 \\\n",
    "    --num-epochs 20 --eval-steps 100 --save-steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSLATE-TEST\n",
    "! python mlm_inference.py \\\n",
    "    --dataset-path \"../data/mtob_domain_en2fr_nllb_test.csv\" \\\n",
    "    --text-column \"text_fr2en\" \\\n",
    "    --model-path \"../outputs/en_only/xlmr-en-1/checkpoint-1500/\" \\\n",
    "    --output-path \"../outputs/en_only/xlmr-en-1/translate_test_preds.csv\"    \n",
    "    \n",
    "! python mlm_inference.py \\\n",
    "    --dataset-path \"../data/mtob_domain_en2fr_nllb_test.csv\" \\\n",
    "    --text-column \"text_fr\" \\\n",
    "    --model-path \"../outputs/en_only/xlmr-en-1/checkpoint-1500/\" \\\n",
    "    --output-path \"../outputs/en_only/xlmr-en-1/test_preds.csv\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2deb5",
   "metadata": {},
   "source": [
    "## B. Train on FR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ed24d",
   "metadata": {},
   "source": [
    "### 1. Monolingual PLM (CamemBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149de",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python mlm_finetuning.py --dataset-dir \"../data\" \\\n",
    "    --train-filename \"mtob_domain_en_fr_train.csv\" --val-filename \"mtob_domain_en_fr_val.csv\" \\\n",
    "    --model-name \"camembert\" --language \"french\" --output-dir \"../outputs/en_and_fr\" --run-name \"camembert-1\" \\\n",
    "    --model-max-length 50 --train-batch-size 128 --eval-batch-size 256 --learning-rate 0.00002 \\\n",
    "    --num-epochs 20 --eval-steps 100 --save-steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd12e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python mlm_inference.py \\\n",
    "    --dataset-path \"../data/mtob_domain_en2fr_nllb_test.csv\" \\\n",
    "    --text-column \"text_fr\" \\\n",
    "    --model-path \"../outputs/en_and_fr/camembert-1/checkpoint-800/\" \\\n",
    "    --output-path \"../outputs/en_and_fr/camembert-1/test_preds.csv\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059ac09",
   "metadata": {},
   "source": [
    "## 2. Multilingual PLM (XLM-RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device\n",
      "11 classes: ['messaging', 'calling', 'event', 'timer', 'music', 'weather', 'alarm', 'people', 'reminder', 'recipes', 'news']\n",
      "Initializer tokenizer for FacebookAI/xlm-roberta-base\n",
      "Map: 100%|██████████████████████| 11814/11814 [00:00<00:00, 13059.18 examples/s]\n",
      "Map: 100%|████████████████████████| 1577/1577 [00:00<00:00, 15513.51 examples/s]\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loaded model from FacebookAI/xlm-roberta-base\n",
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"messaging\",\n",
      "    \"1\": \"calling\",\n",
      "    \"2\": \"event\",\n",
      "    \"3\": \"timer\",\n",
      "    \"4\": \"music\",\n",
      "    \"5\": \"weather\",\n",
      "    \"6\": \"alarm\",\n",
      "    \"7\": \"people\",\n",
      "    \"8\": \"reminder\",\n",
      "    \"9\": \"recipes\",\n",
      "    \"10\": \"news\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"alarm\": 6,\n",
      "    \"calling\": 1,\n",
      "    \"event\": 2,\n",
      "    \"messaging\": 0,\n",
      "    \"music\": 4,\n",
      "    \"news\": 10,\n",
      "    \"people\": 7,\n",
      "    \"recipes\": 9,\n",
      "    \"reminder\": 8,\n",
      "    \"timer\": 3,\n",
      "    \"weather\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Trainable params: 278052107 || all params: 278052107 || trainable%: 100.0\n",
      "Saving outputs to ../outputs/en_and_fr/xlmr-fr-1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manupath\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/anupath/wn24/si630/project/scripts/wandb/run-20240426_201312-od06uehf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mxlmr-fr-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project/runs/od06uehf\u001b[0m\n",
      "  5%|██▏                                     | 100/1860 [00:25<07:19,  4.00it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.55it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.82it/s]\u001b[A\n",
      " 86%|██████████████████████████████████████▌      | 6/7 [00:00<00:00,  8.96it/s]\u001b[A\n",
      "{'eval_loss': 0.20448027551174164, 'eval_f1': 0.9606848446417248, 'eval_precision': 0.9606848446417248, 'eval_recall': 0.9606848446417248, 'eval_macro_f1': 0.9555057631297911, 'eval_weighted_f1': 0.9602554921026084, 'eval_runtime': 0.8257, 'eval_samples_per_second': 1909.839, 'eval_steps_per_second': 8.477, 'epoch': 1.08}\n",
      "\n",
      "  5%|██▏                                     | 100/1860 [00:26<07:19,  4.00it/s]\u001b[A\n",
      " 11%|████▎                                   | 200/1860 [01:08<07:00,  3.95it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.79it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.87it/s]\u001b[A\n",
      " 86%|██████████████████████████████████████▌      | 6/7 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "{'eval_loss': 0.1035892590880394, 'eval_f1': 0.9784400760938491, 'eval_precision': 0.9784400760938491, 'eval_recall': 0.9784400760938491, 'eval_macro_f1': 0.9764292015823585, 'eval_weighted_f1': 0.9784392157258706, 'eval_runtime': 0.8249, 'eval_samples_per_second': 1911.708, 'eval_steps_per_second': 8.486, 'epoch': 2.15}\n",
      "\n",
      " 11%|████▎                                   | 200/1860 [01:09<07:00,  3.95it/s]\u001b[A\n",
      " 16%|██████▍                                 | 300/1860 [01:54<06:36,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.60it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A                                                                             {'eval_loss': 0.07664074003696442, 'eval_f1': 0.9854153455928979, 'eval_precision': 0.9854153455928979, 'eval_recall': 0.9854153455928979, 'eval_macro_f1': 0.983628730655337, 'eval_weighted_f1': 0.9853852511569865, 'eval_runtime': 0.8251, 'eval_samples_per_second': 1911.306, 'eval_steps_per_second': 8.484, 'epoch': 3.23}\n",
      " 16%|██████▍                                 | 300/1860 [01:55<06:36,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.95it/s]\u001b[A\n",
      " 22%|████████▌                               | 400/1860 [02:38<06:10,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.69it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.0802609771490097, 'eval_f1': 0.9822447685478757, 'eval_precision': 0.9822447685478757, 'eval_recall': 0.9822447685478757, 'eval_macro_f1': 0.9802663136271601, 'eval_weighted_f1': 0.9822309216318168, 'eval_runtime': 0.8238, 'eval_samples_per_second': 1914.292, 'eval_steps_per_second': 8.497, 'epoch': 4.3}\n",
      " 22%|████████▌                               | 400/1860 [02:38<06:10,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "{'loss': 0.3638, 'grad_norm': 5.525158882141113, 'learning_rate': 1.4623655913978497e-05, 'epoch': 5.38}\n",
      " 27%|██████████▊                             | 500/1860 [03:15<05:46,  3.93it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.67it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07889875024557114, 'eval_f1': 0.984147114774889, 'eval_precision': 0.984147114774889, 'eval_recall': 0.984147114774889, 'eval_macro_f1': 0.9827590204501387, 'eval_weighted_f1': 0.9841087394682951, 'eval_runtime': 0.8061, 'eval_samples_per_second': 1956.302, 'eval_steps_per_second': 8.684, 'epoch': 5.38}\n",
      " 27%|██████████▊                             | 500/1860 [03:16<05:46,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.93it/s]\u001b[A\n",
      " 32%|████████████▉                           | 600/1860 [04:03<05:20,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.54it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07337484508752823, 'eval_f1': 0.9866835764109068, 'eval_precision': 0.9866835764109068, 'eval_recall': 0.9866835764109068, 'eval_macro_f1': 0.9849733818994704, 'eval_weighted_f1': 0.9866480894588063, 'eval_runtime': 0.8294, 'eval_samples_per_second': 1901.29, 'eval_steps_per_second': 8.439, 'epoch': 6.45}\n",
      " 32%|████████████▉                           | 600/1860 [04:04<05:20,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.91it/s]\u001b[A\n",
      " 38%|███████████████                         | 700/1860 [04:41<04:55,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.51it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07329150289297104, 'eval_f1': 0.9860494610019024, 'eval_precision': 0.9860494610019024, 'eval_recall': 0.9860494610019024, 'eval_macro_f1': 0.9844920282315536, 'eval_weighted_f1': 0.9860370609471222, 'eval_runtime': 0.8242, 'eval_samples_per_second': 1913.385, 'eval_steps_per_second': 8.493, 'epoch': 7.53}\n",
      " 38%|███████████████                         | 700/1860 [04:42<04:55,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.96it/s]\u001b[A\n",
      " 43%|█████████████████▏                      | 800/1860 [05:24<04:29,  3.94it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.67it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.08573170751333237, 'eval_f1': 0.9860494610019024, 'eval_precision': 0.9860494610019024, 'eval_recall': 0.9860494610019024, 'eval_macro_f1': 0.9836399428352549, 'eval_weighted_f1': 0.9859980783026351, 'eval_runtime': 0.8255, 'eval_samples_per_second': 1910.388, 'eval_steps_per_second': 8.48, 'epoch': 8.6}\n",
      " 43%|█████████████████▏                      | 800/1860 [05:25<04:29,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.95it/s]\u001b[A\n",
      " 48%|███████████████████▎                    | 900/1860 [06:02<04:05,  3.92it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.42it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07163258641958237, 'eval_f1': 0.9879518072289156, 'eval_precision': 0.9879518072289156, 'eval_recall': 0.9879518072289156, 'eval_macro_f1': 0.9859822517561256, 'eval_weighted_f1': 0.9879385384315345, 'eval_runtime': 0.8294, 'eval_samples_per_second': 1901.361, 'eval_steps_per_second': 8.44, 'epoch': 9.68}\n",
      " 48%|███████████████████▎                    | 900/1860 [06:02<04:05,  3.92it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.89it/s]\u001b[A\n",
      "{'loss': 0.0203, 'grad_norm': 0.53348708152771, 'learning_rate': 9.24731182795699e-06, 'epoch': 10.75}\n",
      " 54%|████████████████████▉                  | 1000/1860 [06:38<03:38,  3.93it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.45it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07805325090885162, 'eval_f1': 0.9866835764109068, 'eval_precision': 0.9866835764109068, 'eval_recall': 0.9866835764109068, 'eval_macro_f1': 0.9849988600155044, 'eval_weighted_f1': 0.9866601953560944, 'eval_runtime': 0.808, 'eval_samples_per_second': 1951.703, 'eval_steps_per_second': 8.663, 'epoch': 10.75}\n",
      " 54%|████████████████████▉                  | 1000/1860 [06:39<03:38,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.91it/s]\u001b[A\n",
      " 59%|███████████████████████                | 1100/1860 [07:14<03:13,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.62it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.08533232659101486, 'eval_f1': 0.9879518072289156, 'eval_precision': 0.9879518072289156, 'eval_recall': 0.9879518072289156, 'eval_macro_f1': 0.9860258514796431, 'eval_weighted_f1': 0.9879095640267711, 'eval_runtime': 0.8269, 'eval_samples_per_second': 1907.061, 'eval_steps_per_second': 8.465, 'epoch': 11.83}\n",
      " 59%|███████████████████████                | 1100/1860 [07:15<03:13,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.92it/s]\u001b[A\n",
      " 65%|█████████████████████████▏             | 1200/1860 [07:57<02:48,  3.92it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.71it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.07616684585809708, 'eval_f1': 0.9885859226379201, 'eval_precision': 0.9885859226379201, 'eval_recall': 0.9885859226379201, 'eval_macro_f1': 0.9870481348985686, 'eval_weighted_f1': 0.9885546369870089, 'eval_runtime': 0.828, 'eval_samples_per_second': 1904.639, 'eval_steps_per_second': 8.454, 'epoch': 12.9}\n",
      " 65%|█████████████████████████▏             | 1200/1860 [07:58<02:48,  3.92it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.91it/s]\u001b[A\n",
      " 70%|███████████████████████████▎           | 1300/1860 [08:40<02:22,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.67it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.09208071231842041, 'eval_f1': 0.9847812301838935, 'eval_precision': 0.9847812301838935, 'eval_recall': 0.9847812301838935, 'eval_macro_f1': 0.9825335075893843, 'eval_weighted_f1': 0.9847274192939612, 'eval_runtime': 0.825, 'eval_samples_per_second': 1911.575, 'eval_steps_per_second': 8.485, 'epoch': 13.98}\n",
      " 70%|███████████████████████████▎           | 1300/1860 [08:41<02:22,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████▎         | 1400/1860 [09:20<01:53,  4.04it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.73it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.08535166829824448, 'eval_f1': 0.9879518072289156, 'eval_precision': 0.9879518072289156, 'eval_recall': 0.9879518072289156, 'eval_macro_f1': 0.9862041886950507, 'eval_weighted_f1': 0.9879093083362208, 'eval_runtime': 0.8254, 'eval_samples_per_second': 1910.664, 'eval_steps_per_second': 8.481, 'epoch': 15.05}\n",
      " 75%|█████████████████████████████▎         | 1400/1860 [09:21<01:53,  4.04it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.94it/s]\u001b[A\n",
      "{'loss': 0.0057, 'grad_norm': 0.04258784279227257, 'learning_rate': 3.870967741935484e-06, 'epoch': 16.13}\n",
      " 81%|███████████████████████████████▍       | 1500/1860 [10:04<01:31,  3.94it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.63it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.08859910815954208, 'eval_f1': 0.9879518072289156, 'eval_precision': 0.9879518072289156, 'eval_recall': 0.9879518072289156, 'eval_macro_f1': 0.9862041886950507, 'eval_weighted_f1': 0.9879093083362208, 'eval_runtime': 0.8088, 'eval_samples_per_second': 1949.921, 'eval_steps_per_second': 8.655, 'epoch': 16.13}\n",
      " 81%|███████████████████████████████▍       | 1500/1860 [10:05<01:31,  3.94it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.86it/s]\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 1600/1860 [10:48<01:06,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.63it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.80it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.09282086789608002, 'eval_f1': 0.9854153455928979, 'eval_precision': 0.9854153455928979, 'eval_recall': 0.9854153455928979, 'eval_macro_f1': 0.9833720187795876, 'eval_weighted_f1': 0.9853650776702808, 'eval_runtime': 0.8268, 'eval_samples_per_second': 1907.373, 'eval_steps_per_second': 8.466, 'epoch': 17.2}\n",
      " 86%|█████████████████████████████████▌     | 1600/1860 [10:49<01:06,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.92it/s]\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 1700/1860 [11:26<00:40,  3.92it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.73it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.09417099505662918, 'eval_f1': 0.9866835764109068, 'eval_precision': 0.9866835764109068, 'eval_recall': 0.9866835764109068, 'eval_macro_f1': 0.9847704700023147, 'eval_weighted_f1': 0.9866390805959709, 'eval_runtime': 0.8274, 'eval_samples_per_second': 1906.051, 'eval_steps_per_second': 8.461, 'epoch': 18.28}\n",
      " 91%|███████████████████████████████████▋   | 1700/1860 [11:27<00:40,  3.92it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.90it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████▋ | 1800/1860 [12:09<00:15,  3.93it/s]\u001b[A\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:00, 15.73it/s]\u001b[A\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  9.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.09032843261957169, 'eval_f1': 0.9873176918199112, 'eval_precision': 0.9873176918199112, 'eval_recall': 0.9873176918199112, 'eval_macro_f1': 0.9853451385481226, 'eval_weighted_f1': 0.9872820834281126, 'eval_runtime': 0.8269, 'eval_samples_per_second': 1907.116, 'eval_steps_per_second': 8.465, 'epoch': 19.35}\n",
      " 97%|█████████████████████████████████████▋ | 1800/1860 [12:09<00:15,  3.93it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00,  8.92it/s]\u001b[A\n",
      "{'train_runtime': 771.3568, 'train_samples_per_second': 306.317, 'train_steps_per_second': 2.411, 'train_loss': 0.10518794594913401, 'epoch': 20.0}\n",
      "100%|███████████████████████████████████████| 1860/1860 [12:48<00:00,  2.42it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/f1 ▁▅▇▆▇█▇▇████▇██▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss █▃▁▁▁▁▁▂▁▁▂▁▂▂▂▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/macro_f1 ▁▆▇▆▇█▇▇████▇██▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/precision ▁▅▇▆▇█▇▇████▇██▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/recall ▁▅▇▆▇█▇▇████▇██▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ▇▇▇▆▁█▆▇█▂▇█▇▇▂▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▂▂▂▃█▁▃▂▁▇▂▁▂▂▇▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▂▂▂▃█▁▃▂▁▇▂▁▂▂▇▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/weighted_f1 ▁▅▇▆▇█▇▇████▇██▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/f1 0.98732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 0.09033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/macro_f1 0.98535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/precision 0.98732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/recall 0.98732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 0.8269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 1907.116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 8.465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/weighted_f1 0.98728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 5585846824277280.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 1860\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.04259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.0057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.10519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 771.3568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 306.317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 2.411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mxlmr-fr-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project/runs/od06uehf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/anupath/SI630-Project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240426_201312-od06uehf/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python mlm_finetuning.py --dataset-dir \"../data\" \\\n",
    "    --train-filename \"mtob_domain_en_fr_train.csv\" --val-filename \"mtob_domain_en_fr_val.csv\" \\\n",
    "    --model-name \"xlm-roberta\" --language \"french\" --output-dir \"../outputs/en_and_fr\" --run-name \"xlmr-fr-1\" \\\n",
    "    --model-max-length 50 --train-batch-size 128 --eval-batch-size 256 --learning-rate 0.00002 \\\n",
    "    --num-epochs 20 --eval-steps 100 --save-steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python mlm_inference.py \\\n",
    "    --dataset-path \"../data/mtob_domain_en2fr_nllb_test.csv\" \\\n",
    "    --text-column \"text_fr\" \\\n",
    "    --model-path \"../outputs/en_and_fr/xlmr-fr-1/checkpoint-1200/\" \\\n",
    "    --output-path \"../outputs/en_and_fr/xlmr-fr-1/test_preds.csv\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44344d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
